# @package _global_

# to execute this experiment run:
# python run.py experiment=mnli

defaults:
  - override /trainer: default.yaml # choose trainer from 'configs/trainer/'
  - override /module: token_classification.yaml
  - override /datamodule: wikiann_zs.yaml
  - override /callbacks: null
  - override /config_callbacks: trident.yaml
  - override /logger: wandb.yaml

seed: 42
source_lang: en

trainer:
  max_epochs: ???
  gpus: 1
  precision: 16
  num_sanity_val_steps: 0
  deterministic: true
  enable_checkpointing: true

module:
  _target_: src.projects.robust.module.RobustTokenClassification
  optimizer:
    lr: ???
  # dim equals h in the paper
  dim: ???

logger:
  wandb:
    project: "wikiann-zs-repro"
    name: "seed=${seed}-lr=${module.optimizer.lr}-epochs=${trainer.max_epochs}-h=${module.dim}"

callbacks:
  model_checkpoint_on_epoch:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    monitor: null # name of the logged metric which determines when model is improving
    mode: "max" # can be "max" or "min"
    every_n_epochs: 10 # truncated length of MNLI train / 16
    verbose: true
    save_top_k: -1 # -1 -> all models are saved
    save_last: false # additionaly always save model from last epoch
    dirpath: "checkpoints/"
    auto_insert_metric_name: false
